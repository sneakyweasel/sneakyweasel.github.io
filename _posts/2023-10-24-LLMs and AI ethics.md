---
layout: post
title:  "LLMs and AI ethics"
date:   2023-10-24 16:13:05 +0200
categories: AI
---

I've been working on LLMs for a while now and I've been working with various high level thinktanks to try to understand the philosophical, moral and ethical implications of LLMs.

Often it feels there's a real disconnect between the technical community and the ethical community. Explaining the inner working of LLMs to a non-technical person is really hard and I've been trying to find ways to make it easier.

I recently gave a talk to a panel of 10 high-level ethicists with background in philosophy, bio-ethics and theology and here are some key points from our discussion.

## Science-fiction and bad journalism

A lot of science fiction movies depict AI as a supernatural force which is generated by nerd goblins in a dark basement. This is not the case. AI is just a bunch of math and statistics. It's not magic just convenient for lazy scenarists.

Most journalists have a very shallow understanding of AI and they often write articles that are not accurate. This is a real problem because it creates a lot of fear and misunderstanding.

## LLMs are just predicting the next word

It is a sequential model that tries to predict the next word based on the previous words. It's not magic. It is a deterministic process selecting the next token in a sequence therefore nowhere close to human intelligence.

## What is the status of machine-generated speech?

On a philosophical level, next token prediction cannot really be considered on the same level as human thought even if it's really efficient in pretending to be.

## How large are the english culture bias in LLMs?

Most of the training data comes from the internet and the internet is mostly in english. This means that LLMs are really good at english and it seems to push some english culture bias in the generated text that is presented as being neutral.
